{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Reconstructing image with file path faces/superres/truelow0.png, image 1 of 1\n",
      "--------------------------------------------------\n",
      "0.0625\n",
      "Showing (!) the ground truth as training_outputs/0//ground truth at Sun Apr 17 15:19:31 2022.png ...Figure(640x480)\n",
      " done.\n",
      "Saving the corrputed image as training_outputs/0//corrupted at Sun Apr 17 15:19:32 2022.png ...training_outputs/0//corrupted at Sun Apr 17 15:19:32 2022.png (4, 4, 3)\n",
      " done.\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/arthur/miniconda3/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/arthur/Documents/ML/Subhadip/L-BRGM/run.py\", line 72, in <module>\n",
      "    run()\n",
      "  File \"/home/arthur/miniconda3/lib/python3.9/site-packages/click/core.py\", line 1128, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/home/arthur/miniconda3/lib/python3.9/site-packages/click/core.py\", line 1053, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/home/arthur/miniconda3/lib/python3.9/site-packages/click/core.py\", line 1395, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/home/arthur/miniconda3/lib/python3.9/site-packages/click/core.py\", line 754, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/home/arthur/Documents/ML/Subhadip/L-BRGM/run.py\", line 65, in run\n",
      "    model = MODELS[model](**model_args)\n",
      "  File \"/home/arthur/Documents/ML/Subhadip/L-BRGM/models.py\", line 529, in __init__\n",
      "    self.initialise_new_zw()\n",
      "  File \"/home/arthur/Documents/ML/Subhadip/L-BRGM/models.py\", line 542, in initialise_new_zw\n",
      "    if self.get_losses()[\"perceptual\"] < min_percep_loss:\n",
      "  File \"/home/arthur/Documents/ML/Subhadip/L-BRGM/models.py\", line 557, in get_losses\n",
      "    synth_images = self.G.synthesis(self.w2, noise_mode='const')  # G(w)\n",
      "  File \"/home/arthur/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"<string>\", line 463, in forward\n",
      "  File \"/home/arthur/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"<string>\", line 397, in forward\n",
      "  File \"/home/arthur/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"<string>\", line 291, in forward\n",
      "  File \"/home/arthur/Documents/ML/Subhadip/L-BRGM/torch_utils/misc.py\", line 101, in decorator\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"<string>\", line 72, in modulated_conv2d\n",
      "  File \"/home/arthur/Documents/ML/Subhadip/L-BRGM/torch_utils/misc.py\", line 101, in decorator\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/arthur/Documents/ML/Subhadip/L-BRGM/torch_utils/ops/conv2d_resample.py\", line 138, in conv2d_resample\n",
      "    x = _conv2d_wrapper(x=x, w=w, stride=up, padding=[pyt,pxt], groups=groups, transpose=True, flip_weight=(not flip_weight))\n",
      "  File \"/home/arthur/Documents/ML/Subhadip/L-BRGM/torch_utils/ops/conv2d_resample.py\", line 54, in _conv2d_wrapper\n",
      "    return op(x, w, stride=stride, padding=padding, groups=groups)\n",
      "  File \"/home/arthur/Documents/ML/Subhadip/L-BRGM/torch_utils/ops/conv2d_gradfix.py\", line 43, in conv_transpose2d\n",
      "    return torch.nn.functional.conv_transpose2d(input=input, weight=weight, bias=bias, stride=stride, padding=padding, output_padding=output_padding, groups=groups, dilation=dilation)\n",
      "RuntimeError: \"slow_conv_transpose2d_out_cpu\" not implemented for 'Half'\n"
     ]
    }
   ],
   "source": [
    "!python3 run.py --device=cpu --outpath=training_outputs --fpaths=faces/superres/truelow0.png --fpath-corrupted=True --reconstruction-type=superres --input-dim=64 --model=LBRGM"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
